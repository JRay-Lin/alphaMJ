{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahjong DQN Training - Interactive Notebook\n",
    "\n",
    "This notebook provides interactive training for the Mahjong DQN agent with validation between Stage 1 and Stage 2.\n",
    "\n",
    "## Training Pipeline:\n",
    "1. **Stage 1**: Basic win/loss learning (fundamental game knowledge)\n",
    "2. **Validation**: Test Stage 1 model performance\n",
    "3. **Stage 2**: Scoring system integration (strategic depth)\n",
    "4. **Final Evaluation**: Compare Stage 1 vs Stage 2 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport os\nimport sys\nimport json\nimport time\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# Add project root to path\nif '.' not in sys.path:\n    sys.path.append('.')\n\n# Import training modules\nfrom ai.train_stage1 import Stage1Trainer\nfrom ai.train_stage2 import Stage2Trainer\nfrom ai.evaluate import MahjongEvaluator\nfrom ai.dqn_agent import DQNAgent\nfrom ai.utils.config import dqn_config\n\n# Device selection: CUDA > MPS > CPU\ndef get_best_device():\n    if torch.cuda.is_available():\n        return \"cuda\"\n    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n        return \"mps\"\n    else:\n        return \"cpu\"\n\ndevice = get_best_device()\nprint(f\"Training environment ready!\")\nprint(f\"Selected device: {device.upper()}\")\nprint(f\"PyTorch version: {torch.__version__}\")\n\n# Note: Device will be passed to trainers explicitly instead of using set_default_device"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "Configure training parameters for both stages. Adjust these based on your computational resources and time constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training Configuration\nRULE = \"standard\"  # or \"taiwan\"\nDEVICE = device    # Use the automatically selected device (CUDA > MPS > CPU)\n\n# Stage 1 Configuration (Basic Learning with CTDE)\nstage1_config = {\n    'num_episodes': 1000,        # Reduced for notebook testing (normally 10000)\n    'rule_name': RULE,\n    'model_dir': 'ai/models/stage1_notebook',\n    'log_dir': 'ai/logs/stage1_notebook',\n    'centralized_training': True, # Use CTDE for better efficiency\n    'save_frequency': 50,        # Save more frequently for validation\n    'eval_frequency': 100,       # Evaluate more frequently\n    'log_frequency': 10,\n    'target_win_rate': 0.25,\n    'early_stopping_patience': 500,\n    'max_steps_per_episode': 200,\n    'device': DEVICE            # Pass device to training config\n}\n\n# Stage 2 Configuration (Scoring Integration with CTDE)\nstage2_config = {\n    'num_episodes': 1500,        # Reduced for notebook testing (normally 15000)\n    'rule_name': RULE,\n    'model_dir': 'ai/models/stage2_notebook',\n    'log_dir': 'ai/logs/stage2_notebook',\n    'centralized_training': True, # Use CTDE for better efficiency\n    'save_frequency': 50,\n    'eval_frequency': 150,\n    'log_frequency': 10,\n    'target_win_rate': 0.25,\n    'target_avg_score': 50,\n    'early_stopping_patience': 750,\n    'learning_rate_decay': 0.95,\n    'decay_frequency': 500,\n    'curriculum_learning': True,\n    'score_thresholds': [30, 50, 80, 120],\n    'max_steps_per_episode': 200,\n    'device': DEVICE            # Pass device to training config\n}\n\n# Create directories\nos.makedirs(stage1_config['model_dir'], exist_ok=True)\nos.makedirs(stage1_config['log_dir'], exist_ok=True)\nos.makedirs(stage2_config['model_dir'], exist_ok=True)\nos.makedirs(stage2_config['log_dir'], exist_ok=True)\n\nprint(f\"Configuration loaded for {RULE} rule with CTDE\")\nprint(f\"Training device: {DEVICE}\")\nprint(f\"Stage 1: {stage1_config['num_episodes']} episodes\")\nprint(f\"Stage 2: {stage2_config['num_episodes']} episodes\")\nprint(f\"Models will be saved to: {stage1_config['model_dir']} and {stage2_config['model_dir']}\")\nprint(\"ü§ñ Using Centralized Training with Decentralized Execution (CTDE)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Training: Basic Win/Loss Learning\n",
    "\n",
    "First stage focuses on learning fundamental Mahjong rules and basic win/loss patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 1 TRAINING: Basic Win/Loss Learning\n",
      "============================================================\n",
      "Training on device: mps\n",
      "Starting Stage 1 Training: Basic Win/Loss Learning\n",
      "Target episodes: 1000\n",
      "Rule: standard\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Mahjong game...\n",
      "Created Player 1 (AI) with wind: Êù±\n",
      "Created Player 2 (AI) with wind: Âçó\n",
      "Created Player 3 (AI) with wind: Ë•ø\n",
      "Created Player 4 (AI) with wind: Âåó\n",
      "Wall shuffled.\n",
      "Initial hands dealt to all players.\n",
      "Game setup complete. Rule: standard\n",
      "Starting player: Player 1 (AI)\n",
      "\n",
      "‚ùå Stage 1 training failed: Tensor for argument input is on cpu but expected on mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument input is on cpu but expected on mps",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m stage1_trainer = Stage1Trainer(stage1_config)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mstage1_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     stage1_training_time = time.time() - stage1_start_time\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Stage 1 training completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage1_training_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/ai/train_stage1.py:121\u001b[39m, in \u001b[36mStage1Trainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mnum_episodes\u001b[39m\u001b[33m'\u001b[39m]), desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Run episode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     episode_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# Process episode data\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m._process_episode(episode_result, episode)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/ai/training_env.py:361\u001b[39m, in \u001b[36mMultiAgentTrainingEnv.run_episode\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[38;5;66;03m# Get action from agent\u001b[39;00m\n\u001b[32m    360\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m             action, q_values = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m         actions[player_idx] = action\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# Execute actions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/ai/dqn_agent.py:119\u001b[39m, in \u001b[36mDQNAgent.get_action\u001b[39m\u001b[34m(self, state, action_mask, epsilon)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epsilon \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    117\u001b[39m     epsilon = \u001b[38;5;28mself\u001b[39m.epsilon \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/ai/dqn_model.py:117\u001b[39m, in \u001b[36mDuelingDQN.get_action\u001b[39m\u001b[34m(self, state, action_mask, epsilon)\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Still compute Q-values for consistency\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         q_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# Exploitation: best valid action\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/ai/dqn_model.py:75\u001b[39m, in \u001b[36mDuelingDQN.forward\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     73\u001b[39m x = state\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_layers:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     x = F.relu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Value and advantage streams\u001b[39;00m\n\u001b[32m     78\u001b[39m value = \u001b[38;5;28mself\u001b[39m.value_stream(x)  \u001b[38;5;66;03m# [batch_size, 1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repository/alphaMJ/.venv/lib/python3.13/site-packages/torch/utils/_device.py:103\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    102\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Tensor for argument input is on cpu but expected on mps"
     ]
    }
   ],
   "source": [
    "# Stage 1 Training\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 1 TRAINING: Basic Win/Loss Learning\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stage1_start_time = time.time()\n",
    "\n",
    "# Create and run Stage 1 trainer\n",
    "stage1_trainer = Stage1Trainer(stage1_config)\n",
    "\n",
    "try:\n",
    "    stage1_trainer.train()\n",
    "    stage1_training_time = time.time() - stage1_start_time\n",
    "    print(f\"\\n‚úÖ Stage 1 training completed in {stage1_training_time:.1f} seconds\")\n",
    "    \n",
    "    # Check for best model\n",
    "    stage1_best_path = os.path.join(stage1_config['model_dir'], 'best_model.pth')\n",
    "    if os.path.exists(stage1_best_path):\n",
    "        print(f\"‚úÖ Stage 1 best model saved to: {stage1_best_path}\")\n",
    "        stage1_success = True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Stage 1 completed but no best model found\")\n",
    "        stage1_success = False\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚è∏Ô∏è Stage 1 training interrupted by user\")\n",
    "    stage1_success = False\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Stage 1 training failed: {e}\")\n",
    "    stage1_success = False\n",
    "    raise\n",
    "\n",
    "print(f\"\\nStage 1 Status: {'‚úÖ Success' if stage1_success else '‚ùå Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Model Validation\n",
    "\n",
    "Evaluate the Stage 1 model performance before proceeding to Stage 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 Model Validation\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 1 MODEL VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if stage1_success and os.path.exists(stage1_best_path):\n",
    "    try:\n",
    "        # Create evaluator\n",
    "        evaluator = MahjongEvaluator(stage1_best_path, rule=RULE)\n",
    "        \n",
    "        # Run evaluation against random players\n",
    "        print(\"Evaluating Stage 1 model against random players...\")\n",
    "        eval_results = evaluator.evaluate_against_random(num_games=200)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nüìä Stage 1 Evaluation Results:\")\n",
    "        print(f\"   Games Played: {eval_results['games_played']}\")\n",
    "        print(f\"   Win Rate: {eval_results['win_rate']:.3f} ({eval_results['win_rate']*100:.1f}%)\")\n",
    "        print(f\"   Average Score: {eval_results['average_score']:.1f}\")\n",
    "        \n",
    "        if eval_results['game_lengths']:\n",
    "            avg_length = np.mean(eval_results['game_lengths'])\n",
    "            print(f\"   Average Game Length: {avg_length:.1f} turns\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if eval_results['win_rate'] >= 0.20:  # Should be better than random (0.25 is ideal)\n",
    "            print(\"\\n‚úÖ Stage 1 model performance is acceptable\")\n",
    "            print(\"   Ready to proceed to Stage 2 training\")\n",
    "            stage1_validation_passed = True\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Stage 1 model performance is below threshold\")\n",
    "            print(\"   Consider retraining with more episodes\")\n",
    "            stage1_validation_passed = False\n",
    "            \n",
    "        # Generate evaluation plots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Win rate visualization\n",
    "        outcomes = ['Wins', 'Losses', 'Draws']\n",
    "        values = [eval_results['wins'], eval_results['losses'], eval_results['draws']]\n",
    "        colors = ['green', 'red', 'gray']\n",
    "        \n",
    "        axes[0].pie(values, labels=outcomes, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "        axes[0].set_title('Stage 1 Model: Game Outcomes')\n",
    "        \n",
    "        # Score distribution\n",
    "        if eval_results['score_distribution']:\n",
    "            axes[1].hist(eval_results['score_distribution'], bins=20, alpha=0.7, color='blue')\n",
    "            axes[1].set_title('Stage 1 Model: Score Distribution')\n",
    "            axes[1].set_xlabel('Score')\n",
    "            axes[1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Stage 1 validation failed: {e}\")\n",
    "        stage1_validation_passed = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Stage 1 model not available for validation\")\n",
    "    stage1_validation_passed = False\n",
    "\n",
    "print(f\"\\nStage 1 Validation: {'‚úÖ Passed' if stage1_validation_passed else '‚ùå Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Point: Proceed to Stage 2?\n",
    "\n",
    "Based on the validation results above, decide whether to proceed with Stage 2 training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Point\n",
    "print(\"=\" * 60)\n",
    "print(\"DECISION POINT: Proceed to Stage 2?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if stage1_success and stage1_validation_passed:\n",
    "    print(\"‚úÖ Stage 1 training was successful and validation passed\")\n",
    "    print(\"‚úÖ Ready to proceed with Stage 2 training\")\n",
    "    proceed_to_stage2 = True\n",
    "else:\n",
    "    print(\"‚ùå Issues with Stage 1 training or validation\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Re-run Stage 1 with more episodes\")\n",
    "    print(\"2. Adjust Stage 1 configuration\")\n",
    "    print(\"3. Proceed to Stage 2 anyway (not recommended)\")\n",
    "    \n",
    "    # Allow manual override\n",
    "    user_choice = input(\"\\nProceed to Stage 2 anyway? (y/n): \").lower().strip()\n",
    "    proceed_to_stage2 = user_choice in ['y', 'yes']\n",
    "\n",
    "print(f\"\\nDecision: {'Proceed to Stage 2' if proceed_to_stage2 else 'Do not proceed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 Training: Scoring System Integration\n",
    "\n",
    "Second stage focuses on learning strategic depth and scoring optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Training\n",
    "if proceed_to_stage2:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STAGE 2 TRAINING: Scoring System Integration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    stage2_start_time = time.time()\n",
    "    \n",
    "    # Determine pretrained model path\n",
    "    pretrained_path = stage1_best_path if (stage1_success and os.path.exists(stage1_best_path)) else None\n",
    "    \n",
    "    if pretrained_path:\n",
    "        print(f\"Using Stage 1 pretrained model: {pretrained_path}\")\n",
    "        pretrained_dir = os.path.dirname(pretrained_path)\n",
    "    else:\n",
    "        print(\"Starting Stage 2 from scratch (no pretrained model)\")\n",
    "        pretrained_dir = None\n",
    "    \n",
    "    # Create and run Stage 2 trainer\n",
    "    stage2_trainer = Stage2Trainer(stage2_config, pretrained_dir)\n",
    "    \n",
    "    try:\n",
    "        stage2_trainer.train()\n",
    "        stage2_training_time = time.time() - stage2_start_time\n",
    "        print(f\"\\n‚úÖ Stage 2 training completed in {stage2_training_time:.1f} seconds\")\n",
    "        \n",
    "        # Check for best model\n",
    "        stage2_best_path = os.path.join(stage2_config['model_dir'], 'best_model.pth')\n",
    "        if os.path.exists(stage2_best_path):\n",
    "            print(f\"‚úÖ Stage 2 best model saved to: {stage2_best_path}\")\n",
    "            stage2_success = True\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Stage 2 completed but no best model found\")\n",
    "            stage2_success = False\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚è∏Ô∏è Stage 2 training interrupted by user\")\n",
    "        stage2_success = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Stage 2 training failed: {e}\")\n",
    "        stage2_success = False\n",
    "        raise\n",
    "    \n",
    "    print(f\"\\nStage 2 Status: {'‚úÖ Success' if stage2_success else '‚ùå Failed'}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping Stage 2 training\")\n",
    "    stage2_success = False\n",
    "    stage2_best_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Comparison\n",
    "\n",
    "Compare the performance of Stage 1 and Stage 2 models to see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "# Evaluate Stage 1 model\n",
    "if stage1_success and os.path.exists(stage1_best_path):\n",
    "    print(\"\\nüîç Evaluating Stage 1 model...\")\n",
    "    stage1_evaluator = MahjongEvaluator(stage1_best_path, rule=RULE)\n",
    "    stage1_final_results = stage1_evaluator.evaluate_against_random(num_games=500)\n",
    "    comparison_results['stage1'] = stage1_final_results\n",
    "    \n",
    "    print(f\"Stage 1 Final Results:\")\n",
    "    print(f\"   Win Rate: {stage1_final_results['win_rate']:.3f}\")\n",
    "    print(f\"   Average Score: {stage1_final_results['average_score']:.1f}\")\n",
    "\n",
    "# Evaluate Stage 2 model\n",
    "if stage2_success and os.path.exists(stage2_best_path):\n",
    "    print(\"\\nüîç Evaluating Stage 2 model...\")\n",
    "    stage2_evaluator = MahjongEvaluator(stage2_best_path, rule=RULE)\n",
    "    stage2_final_results = stage2_evaluator.evaluate_against_random(num_games=500)\n",
    "    comparison_results['stage2'] = stage2_final_results\n",
    "    \n",
    "    print(f\"Stage 2 Final Results:\")\n",
    "    print(f\"   Win Rate: {stage2_final_results['win_rate']:.3f}\")\n",
    "    print(f\"   Average Score: {stage2_final_results['average_score']:.1f}\")\n",
    "\n",
    "# Compare models if both exist\n",
    "if 'stage1' in comparison_results and 'stage2' in comparison_results:\n",
    "    print(\"\\nüìä Model Comparison:\")\n",
    "    \n",
    "    stage1_wr = comparison_results['stage1']['win_rate']\n",
    "    stage2_wr = comparison_results['stage2']['win_rate']\n",
    "    wr_improvement = ((stage2_wr - stage1_wr) / stage1_wr) * 100\n",
    "    \n",
    "    stage1_score = comparison_results['stage1']['average_score']\n",
    "    stage2_score = comparison_results['stage2']['average_score']\n",
    "    score_improvement = ((stage2_score - stage1_score) / stage1_score) * 100\n",
    "    \n",
    "    print(f\"   Win Rate Improvement: {wr_improvement:+.1f}%\")\n",
    "    print(f\"   Score Improvement: {score_improvement:+.1f}%\")\n",
    "    \n",
    "    if wr_improvement > 0 or score_improvement > 0:\n",
    "        print(\"   ‚úÖ Stage 2 training was beneficial!\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Stage 2 training may need adjustment\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Win rate comparison\n",
    "    models = ['Stage 1', 'Stage 2']\n",
    "    win_rates = [stage1_wr, stage2_wr]\n",
    "    colors = ['lightblue', 'darkblue']\n",
    "    \n",
    "    axes[0].bar(models, win_rates, color=colors)\n",
    "    axes[0].set_title('Win Rate Comparison')\n",
    "    axes[0].set_ylabel('Win Rate')\n",
    "    axes[0].set_ylim(0, max(win_rates) * 1.2)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(win_rates):\n",
    "        axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Score comparison\n",
    "    scores = [stage1_score, stage2_score]\n",
    "    \n",
    "    axes[1].bar(models, scores, color=colors)\n",
    "    axes[1].set_title('Average Score Comparison')\n",
    "    axes[1].set_ylabel('Average Score')\n",
    "    axes[1].set_ylim(0, max(scores) * 1.2)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(scores):\n",
    "        axes[1].text(i, v + 1, f'{v:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüèÅ Training and evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "Summary of the complete training process and final model paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'rule': RULE,\n",
    "    'stage1': {\n",
    "        'success': stage1_success if 'stage1_success' in locals() else False,\n",
    "        'model_path': stage1_best_path if 'stage1_best_path' in locals() and os.path.exists(stage1_best_path) else None,\n",
    "        'episodes': stage1_config['num_episodes'],\n",
    "        'validation_passed': stage1_validation_passed if 'stage1_validation_passed' in locals() else False\n",
    "    },\n",
    "    'stage2': {\n",
    "        'success': stage2_success if 'stage2_success' in locals() else False,\n",
    "        'model_path': stage2_best_path if 'stage2_best_path' in locals() and stage2_best_path and os.path.exists(stage2_best_path) else None,\n",
    "        'episodes': stage2_config['num_episodes'],\n",
    "        'used_pretrained': 'pretrained_path' in locals() and pretrained_path is not None\n",
    "    },\n",
    "    'comparison_results': comparison_results if 'comparison_results' in locals() else {}\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "print(f\"Training Date: {summary['timestamp']}\")\n",
    "print(f\"Rule: {summary['rule']}\")\n",
    "print()\n",
    "print(f\"Stage 1:\")\n",
    "print(f\"   Success: {'‚úÖ' if summary['stage1']['success'] else '‚ùå'}\")\n",
    "print(f\"   Episodes: {summary['stage1']['episodes']}\")\n",
    "print(f\"   Validation: {'‚úÖ Passed' if summary['stage1']['validation_passed'] else '‚ùå Failed'}\")\n",
    "print(f\"   Model: {summary['stage1']['model_path'] or 'Not available'}\")\n",
    "print()\n",
    "print(f\"Stage 2:\")\n",
    "print(f\"   Success: {'‚úÖ' if summary['stage2']['success'] else '‚ùå'}\")\n",
    "print(f\"   Episodes: {summary['stage2']['episodes']}\")\n",
    "print(f\"   Used Pretrained: {'‚úÖ' if summary['stage2']['used_pretrained'] else '‚ùå'}\")\n",
    "print(f\"   Model: {summary['stage2']['model_path'] or 'Not available'}\")\n",
    "\n",
    "# Save summary\n",
    "summary_path = 'ai/training_summary_notebook.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüìÑ Training summary saved to: {summary_path}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "if summary['stage2']['success'] and summary['stage2']['model_path']:\n",
    "    print(f\"1. Test your trained agent: python ai/play_vs_ai.py --models {summary['stage2']['model_path']}\")\n",
    "    print(f\"2. Detailed evaluation: python ai/evaluate.py --model {summary['stage2']['model_path']} --games 1000\")\n",
    "if summary['stage1']['success'] and summary['stage1']['model_path']:\n",
    "    if not summary['stage2']['success']:\n",
    "        print(f\"1. Test Stage 1 agent: python ai/play_vs_ai.py --models {summary['stage1']['model_path']}\")\n",
    "        print(f\"2. Consider re-running Stage 2 with adjusted parameters\")\n",
    "\n",
    "print(\"\\nüéâ Notebook training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphamj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}